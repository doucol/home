#!/usr/bin/env bash
set -e
set -o pipefail

# NOTE: If you are unable to get more than one cluster running, you may need to adjust some kernel settings like so:
# echo fs.inotify.max_user_watches=655360 | sudo tee -a /etc/sysctl.conf
# echo fs.inotify.max_user_instances=1280 | sudo tee -a /etc/sysctl.conf
# sudo sysctl -p

NAME=${NAME:-calico}
VERSION=${VERSION:-master}
SUBNET=${SUBNET:-10.244.0.0/16}
SVCNET=${SVCNET:-10.96.0.0/16}
PORT=${PORT:-6443}
ENCAP=${ENCAP:-VXLANCrossSubnet}
TMPFILE="/tmp/kind-config-${NAME}.values.yaml"
KUBECTL="kubectl --context=kind-${NAME}"
if [[ "${VERSION}" == "lasthash" && "${OPYAML}" == "" ]]; then
  OPYAML=$(curl --silent https://latest-os.docs.eng.tigera.net/master.txt | xargs)manifests/tigera-operator.yaml
fi
if [[ "${VERSION}" == "latest" && "${OPYAML}" == "" ]]; then
  LATEST_TAG=$(curl -s "https://api.github.com/repos/projectcalico/calico/tags" | jq -r '.[].name' | grep -E 'v[0-9]+\.[0-9]+\.[0-9]+$' | head -1 | xargs)
  OPYAML="https://raw.githubusercontent.com/projectcalico/calico/${LATEST_TAG}/manifests/tigera-operator.yaml"
fi
OPYAML=${OPYAML:-"https://raw.githubusercontent.com/projectcalico/calico/${VERSION}/manifests/tigera-operator.yaml"}

cat >"${TMPFILE}" <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
- role: worker
- role: worker
networking:
  disableDefaultCNI: true
  podSubnet: "${SUBNET}"
  serviceSubnet: "${SVCNET}"
  apiServerPort: ${PORT}
EOF

kind delete cluster --name="${NAME}"
kind create cluster --config "${TMPFILE}" --name "${NAME}"

if [[ -f "$HOME/.docker/config.json" ]]; then
  echo "Copying your docker auth secrets ($HOME/.docker/config.json) to each cluster node..."
  for node in $(kind get nodes --name="${NAME}"); do
    docker cp "$HOME/.docker/config.json" "${node}:/var/lib/kubelet/config.json"
    docker exec "${node}" systemctl restart kubelet.service
  done
else
  echo "Warning: no docker auth secret is being applied to the nodes since '$HOME/.docker/config.json' does not exist"
fi

echo "Installing Calico OSS operator using: ${OPYAML}"
${KUBECTL} create -f "${OPYAML}"
while ! ${KUBECTL} wait --for=condition=established --timeout=60s crd/whiskers.operator.tigera.io &>/dev/null; do
  echo "Waiting for Calico CRDs to be created..."
  sleep 2
done

# Create calico custom resource configurations to kick off the install
${KUBECTL} create -f - <<EOF
apiVersion: operator.tigera.io/v1
kind: Installation
metadata:
  name: default
spec:
  registry: docker.io/
  calicoNetwork:
    ipPools:
    - name: default-ipv4-ippool
      blockSize: 26
      cidr: ${SUBNET}
      encapsulation: ${ENCAP}
      natOutgoing: Enabled
      nodeSelector: all()
---
apiVersion: operator.tigera.io/v1
kind: APIServer
metadata:
  name: default
spec: {}
---
apiVersion: operator.tigera.io/v1
kind: Whisker
metadata:
  name: default
EOF
#${KUBECTL} create -f "https://raw.githubusercontent.com/projectcalico/calico/${VERSION}/manifests/custom-resources.yaml"

while ! ${KUBECTL} wait --for='jsonpath={.status.conditions[?(@.type=="Available")].status}=True' --timeout=60s --all tigerastatuses 2>/dev/null; do
  echo "Waiting for all 'tigerastatus' resources to become available..."
  sleep 2
done

if ! ${KUBECTL} wait --for='jsonpath={.status.conditions[?(@.type=="Available")].status}=True' --timeout=10s tigerastatuses/whisker &>/dev/null; then
  # Without restarting the operator it is hit-or-miss on whether we'll have whisker reliably deployed - need to dig into this more later
  echo ""
  echo "Whisker not yet deployed! -- restarting the tigera/calico operator to kick the whisker deployment into gear..."
  ${KUBECTL} delete pod --namespace=tigera-operator -l=k8s-app=tigera-operator
  while ! ${KUBECTL} wait --for='jsonpath={.status.conditions[?(@.type=="Available")].status}=True' --timeout=30s tigerastatuses/whisker 2>/dev/null; do
    echo "Waiting for 'tigerastatus/whisker' resource to become available..."
    sleep 2
  done
fi

if [[ "${DEMOAPP}" == "true" ]]; then
  echo ""
  echo "Installing Demo App 'GoogleCloudPlatform/microservices-demo'..."
  ${KUBECTL} create -f https://raw.githubusercontent.com/GoogleCloudPlatform/microservices-demo/refs/heads/main/release/kubernetes-manifests.yaml
fi
